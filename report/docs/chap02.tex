\section{Literature Review}

Previous research in $\mu$RTS has focused on areas such as Monte Carlo tree search (MCTS);
adversarial search algorithms that perform search at some level of abstraction, such as
Puppet Search or adversarial HTN planning; and even deep learning for RTS games\cite{ontanon2018first}.

In 2017, there was a AI competition that hosted at the IEEE Computational Intelligence in
Games (CIG) within the base of microRTS, the goal of that competition is to search for a
better way of artificial intelligence techniques to handle Real-Time Strategy games.
There were three submissions that received by 2017 competition: StrategyTactics\cite{barriga2017combining},
Strategy Creation through Voting (SCV)\cite{silva2018strategy}, and BS3NaiveMCTS\cite{uriarte2015automatic}.
The StrategyTactics uses the strategic strength of PuppetSearch and tactical performance of NaiveMCTS
to achieve algorithms which performs well of making low-level decisions of complex game state with
higher branching factors or long-term actions consequence. SCV uses a set of built-in
strategies to create different and new strategies to adapt changeable game state. BS3NaiveMCTS
is an extension of NaiveMCTS to deal with the situation that when the map is partial observed
in RTS games. However, the bot strategy that our group built draws on the advantages of the first
two approaches, using decision tree to judge the game state and implement a portfolio build-in
strategy for different situations.
